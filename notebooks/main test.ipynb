{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gyova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, LSTM, SimpleRNN, Conv1D, Dense, Dropout, Attention, Bidirectional\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "log_dir = \"logs/\"  # Especifique o diretório onde os logs serão armazenados\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                False\n",
       "preprocessed_news    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dataset1.csv')\n",
    "df = df.drop(columns=['index'])\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "def remover_stop_words(news):\n",
    "    palavras = news.split()\n",
    "    palavras_sem_stop = [palavra for palavra in palavras if palavra.lower() not in stop_words]\n",
    "    return ' '.join(palavras_sem_stop)\n",
    "\n",
    "def review_cleaning(text):\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "df[\"preprocessed_news\"] = df[\"preprocessed_news\"].apply(remover_stop_words)\n",
    "df['label'] = df.apply(lambda row: 0 if row.label == 'fake' else 1, axis=1)\n",
    "X = df.drop(['label'], axis = 1)\n",
    "Y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, stratify=Y)\n",
    "X_train = X_train['preprocessed_news'].apply(lambda x: x.lower())\n",
    "X_test = X_test['preprocessed_news'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variaveis dos modelos\n",
    "maxlen=256\n",
    "num_words = 8000\n",
    "batch_size = 128 \n",
    "epochs = 20 \n",
    "validation_fraction = 0.2\n",
    "output_dim = 64\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>',num_words=num_words)\n",
    "train_tokenizer.fit_on_texts(X_train.values)\n",
    "train_word_index = train_tokenizer.word_index\n",
    "train_sequences = train_tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "text_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>',num_words=num_words)\n",
    "text_tokenizer.fit_on_texts(X_test.values)\n",
    "text_word_index = text_tokenizer.word_index\n",
    "text_sequences = text_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_length = len(train_word_index) + 1\n",
    "\n",
    "train_padded_seqeunces = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
    "test_padded_seqeunces = tf.keras.preprocessing.sequence.pad_sequences(text_sequences, maxlen=maxlen)\n",
    "\n",
    "train_padded_seqeunces = train_padded_seqeunces[:, :, tf.newaxis]\n",
    "test_padded_seqeunces = test_padded_seqeunces[:, :, tf.newaxis]\n",
    "\n",
    "x_train_padded_seqeunces = train_padded_seqeunces[:, :, tf.newaxis]\n",
    "x_test_padded_seqeunces = test_padded_seqeunces[:, :, tf.newaxis]\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=num_words)\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train).toarray()\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=num_words)\n",
    "vectorizer.fit(X_test)\n",
    "X_test = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../models/MLPClassifierWithGridSearchCVV2.pkl', 'rb') as arquivo:\n",
    "    clf = pickle.load(arquivo)\n",
    "\n",
    "    \n",
    "modelLSTM = load_model('../models/modelLSTMV2.keras')\n",
    "modelHAN = load_model('../models/modelHAN.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio do Teste\n",
      "====================\n",
      "Matriz de confusão\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim do Teste\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Inicio do Teste\")\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "mlp_acc = round(accuracy_score(y_test, y_test_pred), 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(\"Matriz de confusão\")\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['Fake','True'])\n",
    "disp.plot(cmap='Blues', values_format='.0f')\n",
    "#plt.savefig('../matriz/confusion_matrix_MLP.png')\n",
    "plt.show()\n",
    "print(\"Fim do Teste\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número total de iterações:\", len(mlp_hist.cv_results_['params']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake','True'])\n",
    "disp.plot(values_format='.0f')\n",
    "plt.savefig('../matriz/confusion_matrix_MLP.png')\n",
    "plt.show()\n",
    "print(\"Fim do Teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN (LSTM bidirecionais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"Modelo RNN (LSTM bidirecionais)\")\n",
    "\n",
    "modelLSTM = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_length, output_dim, input_length=maxlen),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10)),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "modelLSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Summary do modelo RNN (LSTM bidirecionais) ')\n",
    "modelLSTM.summary()\n",
    "print()\n",
    "# Função para contar iterações\n",
    "class BatchCounter(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "batch_counter_callback = BatchCounter()\n",
    "\n",
    "\n",
    "print(\"Inciando do treinamento\")\n",
    "historyLSTM = modelLSTM.fit(train_padded_seqeunces, y_train, epochs=epochs, validation_split=0.3, callbacks=[early_stopping,tensorboard_callback,batch_counter_callback])\n",
    "print(\"Fim do treinamento\")\n",
    "\n",
    "LSTM_train = round(historyLSTM.history['accuracy'][-1] * 100, 2)\n",
    "\n",
    "print(\"Salvando modelo\")\n",
    "modelLSTM.save('../models/modelLSTMV2.keras', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total de iterações: {batch_counter_callback.batch_count}')\n",
    "\n",
    "print(\"Inicio do Teste\")\n",
    "\n",
    "y_test_pred = modelLSTM.predict(test_padded_seqeunces)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "lstm_acc = round(accuracy_score(y_test, y_test_pred) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Falsa','Verdadeira'], )\n",
    "disp.plot(values_format='.0f')\n",
    "plt.savefig('../matriz/confusion_matrix_LSTM.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fim dos testes\")\n",
    "\n",
    "print(\"=\" * 30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historyLSTM.history['loss'])\n",
    "plt.title('Model loss progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend(['Training loss'])\n",
    "plt.savefig('../graficos/loss_lstmV2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historyLSTM.history['accuracy'])\n",
    "plt.title('Model accuracy progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training accuracy')\n",
    "plt.legend(['Training accuracy'])\n",
    "plt.savefig('../graficos/accuracy_lstmV2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(modelLSTM, to_file='../summery/lstm.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN (HAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"Modelo RNN (HAN)\")\n",
    "\n",
    "\n",
    "def word_attention(x):\n",
    "    return Attention()([x, x])\n",
    "\n",
    "def sentence_attention(x):\n",
    "    return Attention()([x, x])\n",
    "\n",
    "document_input = Input(shape=(maxlen,))\n",
    "word_embedding = Embedding(vocab_length, output_dim, input_length=maxlen)(document_input)\n",
    "word_lstm = Bidirectional(LSTM(50, return_sequences=True))(word_embedding)\n",
    "word_attention = word_attention(word_lstm)\n",
    "sentence_lstm = Bidirectional(LSTM(20, return_sequences=True))(word_attention)\n",
    "sentence_attention = sentence_attention(sentence_lstm)\n",
    "doc_lstm = Bidirectional(LSTM(10))(sentence_attention)\n",
    "dense_layer = Dense(5, activation='relu')(doc_lstm)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.5)(dense_layer)\n",
    "output = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model_han = tf.keras.Model(inputs=document_input, outputs=output)\n",
    "model_han.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('Summary do modelo RNN (LSTM bidirecionais) ')\n",
    "model_han.summary()\n",
    "print()\n",
    "\n",
    "print(\"Inciando do treinamento\")\n",
    "historyHAN = model_han.fit(train_padded_seqeunces, y_train, epochs=epochs, validation_split=0.2, callbacks=[early_stopping,tensorboard_callback])\n",
    "print(\"Fim do treinamento\")\n",
    "\n",
    "HAN_train = round(historyHAN.history['accuracy'][-1] * 100, 2)\n",
    "\n",
    "print(\"Salvando modelo\")\n",
    "\n",
    "#model_han.save('../models/modelHAN.keras', save_format='tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Inicio do Teste\")\n",
    "y_test_pred = model_han.predict(test_padded_seqeunces)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "han_acc = round(accuracy_score(y_test, y_test_pred) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Falsa','Verdadeira'], )\n",
    "disp.plot(values_format='.0f')\n",
    "plt.savefig('../matriz/confusion_matrix_HAN.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fim dos testes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 30)\n",
    "\n",
    "plt.plot(historyHAN.history['loss'])\n",
    "plt.title('Model loss progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend(['Training loss'])\n",
    "plt.savefig('../graficos/loss_han.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(historyHAN.history['accuracy'])\n",
    "plt.title('Model accuracy progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training accuracy')\n",
    "plt.legend(['Training accuracy'])\n",
    "plt.savefig('../graficos/accuracy_han.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_han, to_file='../summery/han.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio do Teste \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'victor chaves detona rede globo desrespeitosa profana jornalismo nao mostra coisa cantor victor dupla sertaneja victor leo falou poucas boas sobre rede globo atraves redes sociais acusado agredir fisicamente esposa fevereiro deste ano cantor disse globo colocou geladeira jamais pedi sair programa alegaram precisava preservado escreveu victor explicou indiciado vias fato nao crime tudo sera esclarecido rede globo tambem editou partes programa ja gravado tirou literalmente victor cenas inconformado cantor usou instagram desabafar sobre fato'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m modelHAN \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/modelHAN.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInicio do Teste \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmlpG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m (y_test_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.70\u001b[39m)\n\u001b[0;32m     15\u001b[0m han_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_score(y_test, y_test_pred) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\sklearn\\model_selection\\_search.py:519\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/model_selection/_search.py?line=500'>501</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/model_selection/_search.py?line=501'>502</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/model_selection/_search.py?line=502'>503</a>\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/model_selection/_search.py?line=515'>516</a>\u001b[0m \u001b[39m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/model_selection/_search.py?line=516'>517</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/model_selection/_search.py?line=517'>518</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/model_selection/_search.py?line=518'>519</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1160\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1146'>1147</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1147'>1148</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1148'>1149</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1156'>1157</a>\u001b[0m \u001b[39m    The predicted classes.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1157'>1158</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1158'>1159</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1159'>1160</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X)\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1164\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1161'>1162</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1162'>1163</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1163'>1164</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_pass_fast(X, check_input\u001b[39m=\u001b[39;49mcheck_input)\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1165'>1166</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1166'>1167</a>\u001b[0m         y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:207\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=187'>188</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=188'>189</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=189'>190</a>\u001b[0m \u001b[39mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=203'>204</a>\u001b[0m \u001b[39m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=204'>205</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=205'>206</a>\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=206'>207</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=208'>209</a>\u001b[0m \u001b[39m# Initialize first layer\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=209'>210</a>\u001b[0m activation \u001b[39m=\u001b[39m X\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/base.py?line=601'>602</a>\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/base.py?line=602'>603</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/base.py?line=603'>604</a>\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/base.py?line=604'>605</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/base.py?line=605'>606</a>\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/validation.py?line=914'>915</a>\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/validation.py?line=915'>916</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/validation.py?line=916'>917</a>\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/validation.py?line=917'>918</a>\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/validation.py?line=918'>919</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/validation.py?line=919'>920</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/validation.py?line=920'>921</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/_array_api.py?line=377'>378</a>\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/_array_api.py?line=378'>379</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/_array_api.py?line=379'>380</a>\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/_array_api.py?line=381'>382</a>\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/_array_api.py?line=382'>383</a>\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/sklearn/utils/_array_api.py?line=383'>384</a>\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\gyova\\Documents\\Projetos\\Model-dectation-fake-news\\ven\\lib\\site-packages\\pandas\\core\\series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=869'>870</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=870'>871</a>\u001b[0m \u001b[39mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=871'>872</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=913'>914</a>\u001b[0m \u001b[39m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=914'>915</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=915'>916</a>\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m--> <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=916'>917</a>\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(values, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=917'>918</a>\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    <a href='file:///c%3A/Users/gyova/Documents/Projetos/Model-dectation-fake-news/ven/lib/site-packages/pandas/core/series.py?line=918'>919</a>\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'victor chaves detona rede globo desrespeitosa profana jornalismo nao mostra coisa cantor victor dupla sertaneja victor leo falou poucas boas sobre rede globo atraves redes sociais acusado agredir fisicamente esposa fevereiro deste ano cantor disse globo colocou geladeira jamais pedi sair programa alegaram precisava preservado escreveu victor explicou indiciado vias fato nao crime tudo sera esclarecido rede globo tambem editou partes programa ja gravado tirou literalmente victor cenas inconformado cantor usou instagram desabafar sobre fato'"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('../models/MLPClassifierWithGridSearchCVV2.pkl', 'rb') as arquivo:\n",
    "    mlpG = pickle.load(arquivo)\n",
    "\n",
    "    \n",
    "modelLSTM = load_model('../models/modelLSTMV2.keras')\n",
    "modelHAN = load_model('../models/modelHAN.keras')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Inicio do Teste \")\n",
    "y_test_pred = mlpG.predict(X_test)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "han_acc = round(accuracy_score(y_test, y_test_pred) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Falsa','Verdadeira'], )\n",
    "disp.plot(values_format='.0f')\n",
    "#plt.savefig('../matriz/confusion_matrix_HAN%.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fim dos testes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpG_train =  round(mlp_hist.best_score_ * 100, 0)\n",
    "mlp_acc =  round(mlp_hist.best_estimator_.score(X_test, y_test) * 100, 0)\n",
    "LSTM_train = round(historyLSTM.history['accuracy'][-1] * 100, 0)\n",
    "lstm_acc = round(accuracy_score(y_test, y_test_pred) * 100, 0)\n",
    "HAN_train = round(historyHAN.history['accuracy'][-1] * 100, 0)\n",
    "han_acc = round(accuracy_score(y_test, y_test_pred) * 100, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'MLP',\n",
    "        'RNN LSTM(BI)',\n",
    "        'HAN'\n",
    "    ],\n",
    "    'Train Accuracy Score': [\n",
    "        \n",
    "        mlpG_train ,LSTM_train,HAN_train\n",
    "    ],\n",
    "    'Test Accuracy': [\n",
    "        \n",
    "        mlp_acc ,lstm_acc,han_acc\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = model.sort_values('Test Accuracy',ascending=False)\n",
    "Train"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45f1f3757439874319ad1023556b798bdce3a703ab4652de42b8220c6c143c8c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ven': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
