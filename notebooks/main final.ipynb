{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gyova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, LSTM, SimpleRNN, Conv1D, Dense, Dropout, Attention, Bidirectional\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "log_dir = \"logs/\"  # Especifique o diretório onde os logs serão armazenados\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                False\n",
       "preprocessed_news    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/fakeBr.csv')\n",
    "df = df.drop(columns=['index'])\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "def remover_stop_words(news):\n",
    "    palavras = news.split()\n",
    "    palavras_sem_stop = [palavra for palavra in palavras if palavra.lower() not in stop_words]\n",
    "    return ' '.join(palavras_sem_stop)\n",
    "\n",
    "def review_cleaning(text):\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "df[\"preprocessed_news\"] = df[\"preprocessed_news\"].apply(remover_stop_words)\n",
    "df['label'] = df.apply(lambda row: 0 if row.label == 'fake' else 1, axis=1)\n",
    "X = df.drop(['label'], axis = 1)\n",
    "Y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, stratify=Y)\n",
    "X_train = X_train['preprocessed_news'].apply(lambda x: x.lower())\n",
    "X_test = X_test['preprocessed_news'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variaveis dos modelos\n",
    "maxlen=256\n",
    "num_words = 8000\n",
    "batch_size = 128 \n",
    "epochs = 20 \n",
    "validation_fraction = 0.2\n",
    "output_dim = 64\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>',num_words=num_words)\n",
    "train_tokenizer.fit_on_texts(X_train.values)\n",
    "train_word_index = train_tokenizer.word_index\n",
    "train_sequences = train_tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "text_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>',num_words=num_words)\n",
    "text_tokenizer.fit_on_texts(X_test.values)\n",
    "text_word_index = text_tokenizer.word_index\n",
    "text_sequences = text_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_length = len(train_word_index) + 1\n",
    "\n",
    "train_padded_seqeunces = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
    "test_padded_seqeunces = tf.keras.preprocessing.sequence.pad_sequences(text_sequences, maxlen=maxlen)\n",
    "\n",
    "train_padded_seqeunces = train_padded_seqeunces[:, :, tf.newaxis]\n",
    "test_padded_seqeunces = test_padded_seqeunces[:, :, tf.newaxis]\n",
    "\n",
    "x_train_padded_seqeunces = train_padded_seqeunces[:, :, tf.newaxis]\n",
    "x_test_padded_seqeunces = test_padded_seqeunces[:, :, tf.newaxis]\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=num_words)\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train).toarray()\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=num_words)\n",
    "vectorizer.fit(X_test)\n",
    "X_test = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"Modelo Multi Layers Perceptron\")\n",
    "\n",
    "parameters = {'solver': ['sgd', 'lbfgs'],\n",
    "              'hidden_layer_sizes':[(30, 20, 10)],\n",
    "              'random_state':[2],\n",
    "              'activation':  ['relu', 'tanh', 'logistic'],\n",
    "              'max_iter': [400],\n",
    "              'alpha': [0.0001, 0.001, 0.01],\n",
    "              \"batch_size\" : [128],\n",
    "              \"learning_rate_init\": [0.002],\n",
    "              'learning_rate': ['adaptive','constant'],\n",
    "              \"validation_fraction\":[0.2],\n",
    "              }\n",
    "\n",
    "param = {'activation': ['logistic'], 'alpha': [0.0001], 'batch_size': [128], 'hidden_layer_sizes': (30, 20, 10), 'learning_rate': ['adaptive'],\n",
    "                                               'learning_rate_init': [0.002], 'max_iter': [maxlen], 'solver': ['sgd'], 'validation_fraction': [validation_fraction]}\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(), param, cv=3, verbose=10)\n",
    "mlp_hist = clf.fit(X_train,y_train)\n",
    "mlpG_train = round(clf.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "print(\"Fim do treinamento MLP\")\n",
    "\n",
    "print()\n",
    "print(\"Melhores parametros :\", mlp_hist.best_params_)\n",
    "print(\"Train accuracy:\", mlp_hist.best_score_)\n",
    "print(\"Test accuracy:\", mlp_hist.best_estimator_.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "print(\"Salvando modelo\")\n",
    "with open('../models/MLPClassifierWithGridSearchCV.pkl', 'wb') as arquivo:\n",
    "    pickle.dump(clf, arquivo)\n",
    "print(\"Inicio do Teste\")\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "mlp_acc = round(accuracy_score(y_test, y_test_pred), 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake','True'])\n",
    "disp.plot(cmap='Blues', values_format='.0f')\n",
    "plt.savefig('../matriz/confusion_matrix_MLP.png')\n",
    "plt.show()\n",
    "print(\"Fim do Teste\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número total de iterações:\", len(mlp_hist.cv_results_['params']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake','True'])\n",
    "disp.plot(values_format='.0f')\n",
    "plt.savefig('../matriz/confusion_matrix_MLP.png')\n",
    "plt.show()\n",
    "print(\"Fim do Teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN (LSTM bidirecionais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"Modelo RNN (LSTM bidirecionais)\")\n",
    "\n",
    "modelLSTM = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_length, output_dim, input_length=maxlen),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10)),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "modelLSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Summary do modelo RNN (LSTM bidirecionais) ')\n",
    "modelLSTM.summary()\n",
    "print()\n",
    "# Função para contar iterações\n",
    "class BatchCounter(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "batch_counter_callback = BatchCounter()\n",
    "\n",
    "\n",
    "print(\"Inciando do treinamento\")\n",
    "historyLSTM = modelLSTM.fit(train_padded_seqeunces, y_train, epochs=epochs, validation_split=0.3, callbacks=[early_stopping,tensorboard_callback,batch_counter_callback])\n",
    "print(\"Fim do treinamento\")\n",
    "\n",
    "LSTM_train = round(historyLSTM.history['accuracy'][-1] * 100, 2)\n",
    "\n",
    "print(\"Salvando modelo\")\n",
    "modelLSTM.save('../models/modelLSTMV2.keras', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total de iterações: {batch_counter_callback.batch_count}')\n",
    "\n",
    "print(\"Inicio do Teste\")\n",
    "\n",
    "y_test_pred = modelLSTM.predict(test_padded_seqeunces)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "lstm_acc = round(accuracy_score(y_test, y_test_pred) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Falsa','Verdadeira'], )\n",
    "disp.plot(values_format='.0f')\n",
    "plt.savefig('../matriz/confusion_matrix_LSTM.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fim dos testes\")\n",
    "\n",
    "print(\"=\" * 30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historyLSTM.history['loss'])\n",
    "plt.title('Model loss progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend(['Training loss'])\n",
    "plt.savefig('../graficos/loss_lstmV2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historyLSTM.history['accuracy'])\n",
    "plt.title('Model accuracy progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training accuracy')\n",
    "plt.legend(['Training accuracy'])\n",
    "plt.savefig('../graficos/accuracy_lstmV2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(modelLSTM, to_file='../summery/lstm.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN (HAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"Modelo RNN (HAN)\")\n",
    "\n",
    "\n",
    "def word_attention(x):\n",
    "    return Attention()([x, x])\n",
    "\n",
    "def sentence_attention(x):\n",
    "    return Attention()([x, x])\n",
    "\n",
    "document_input = Input(shape=(maxlen,))\n",
    "word_embedding = Embedding(vocab_length, output_dim, input_length=maxlen)(document_input)\n",
    "word_lstm = Bidirectional(LSTM(50, return_sequences=True))(word_embedding)\n",
    "word_attention = word_attention(word_lstm)\n",
    "sentence_lstm = Bidirectional(LSTM(20, return_sequences=True))(word_attention)\n",
    "sentence_attention = sentence_attention(sentence_lstm)\n",
    "doc_lstm = Bidirectional(LSTM(10))(sentence_attention)\n",
    "dense_layer = Dense(5, activation='relu')(doc_lstm)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.5)(dense_layer)\n",
    "output = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model_han = tf.keras.Model(inputs=document_input, outputs=output)\n",
    "model_han.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('Summary do modelo RNN (LSTM bidirecionais) ')\n",
    "model_han.summary()\n",
    "print()\n",
    "\n",
    "print(\"Inciando do treinamento\")\n",
    "historyHAN = model_han.fit(train_padded_seqeunces, y_train, epochs=epochs, validation_split=0.2, callbacks=[early_stopping,tensorboard_callback])\n",
    "print(\"Fim do treinamento\")\n",
    "\n",
    "HAN_train = round(historyHAN.history['accuracy'][-1] * 100, 2)\n",
    "\n",
    "print(\"Salvando modelo\")\n",
    "\n",
    "#model_han.save('../models/modelHAN.keras', save_format='tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Inicio do Teste\")\n",
    "y_test_pred = model_han.predict(test_padded_seqeunces)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "han_acc = round(accuracy_score(y_test, y_test_pred) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Falsa','Verdadeira'], )\n",
    "disp.plot(values_format='.0f')\n",
    "plt.savefig('../matriz/confusion_matrix_HAN.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fim dos testes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 30)\n",
    "\n",
    "plt.plot(historyHAN.history['loss'])\n",
    "plt.title('Model loss progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend(['Training loss'])\n",
    "plt.savefig('../graficos/loss_han.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(historyHAN.history['accuracy'])\n",
    "plt.title('Model accuracy progress during training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training accuracy')\n",
    "plt.legend(['Training accuracy'])\n",
    "plt.savefig('../graficos/accuracy_han.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_han, to_file='../summery/han.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../models/MLPClassifierWithGridSearchCVV2.pkl', 'rb') as arquivo:\n",
    "    mlpG = pickle.load(arquivo)\n",
    "    \n",
    "modelLSTM = load_model('../models/modelLSTMV2.keras')\n",
    "modelHAN = load_model('../models/modelHAN.keras')\n",
    "\n",
    "print(\"Inicio do Teste \")\n",
    "y_test_pred = mlpG.predict(X_test)\n",
    "y_test_pred = (y_test_pred > 0.70)\n",
    "han_acc = round(accuracy_score(y_test, y_test_pred) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "print(\"Matriz de confusão\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Falsa','Verdadeira'], )\n",
    "disp.plot(values_format='.0f')\n",
    "#plt.savefig('../matriz/confusion_matrix_HAN%.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fim dos testes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpG_train =  round(mlp_hist.best_score_ * 100, 0)\n",
    "mlp_acc =  round(mlp_hist.best_estimator_.score(X_test, y_test) * 100, 0)\n",
    "LSTM_train = round(historyLSTM.history['accuracy'][-1] * 100, 0)\n",
    "lstm_acc = round(accuracy_score(y_test, y_test_pred) * 100, 0)\n",
    "HAN_train = round(historyHAN.history['accuracy'][-1] * 100, 0)\n",
    "han_acc = round(accuracy_score(y_test, y_test_pred) * 100, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'MLP',\n",
    "        'RNN LSTM(BI)',\n",
    "        'HAN'\n",
    "    ],\n",
    "    'Train Accuracy Score': [\n",
    "        \n",
    "        mlpG_train ,LSTM_train,HAN_train\n",
    "    ],\n",
    "    'Test Accuracy': [\n",
    "        \n",
    "        mlp_acc ,lstm_acc,han_acc\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = model.sort_values('Test Accuracy',ascending=False)\n",
    "Train"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45f1f3757439874319ad1023556b798bdce3a703ab4652de42b8220c6c143c8c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ven': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
